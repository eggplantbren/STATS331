\documentclass{beamer}
\usetheme[pageofpages=of,% String used between the current page and the
                         % total page count.
          bullet=circle,% Use circles instead of squares for bullets.
          titleline=true,% Show a line below the frame title.
          alternativetitlepage=true,% Use the fancy title page.
       %   titlepagelogo=logo-polito,% Logo for the first page.
       %   watermark=watermark-polito,% Watermark used in every page.
       %   watermarkheight=100px,% Height of the watermark.
       %   watermarkheightmult=4,% The watermark image is 4 times bigger
                                % than watermarkheight.
          ]{Torino}

\setbeamertemplate{footline}{
  \begin{beamercolorbox}[wd=\paperwidth,ht=1ex,dp=1ex]{footline}
    \vspace{5pt} \hspace{1em} \insertframenumber/\inserttotalframenumber
  \end{beamercolorbox}
}

\author{Brendon J. Brewer}
\title{STATS 331 -- Introduction to Bayesian Statistics}
\institute{The University of Auckland}
\date{}


\linespread{1.3}
\usepackage{minted}
\usepackage[utf8]{inputenc}
\usepackage{dsfont}
\newcommand{\given}{\,|\,}


\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Probability as Plausibility}
The main distinction between Bayesian and frequentist/classical statistics
is the meaning of probability. What we think a probability {\em is}
influences {\em what calculations we think it is valid to do.}\\[0.5em]\pause

In Bayesian statistics, $P(A \given B)$ means how plausible statement $A$ is,
assuming that $B$ is true (this might be hypothetical --- {\em if} $B$
were true --- or we might actually know $B$ is true).

\end{frame}



\begin{frame}
\frametitle{Example of Probability as Plausibility}
Suppose there is some {\bf statement}
or {\bf proposition} $A$, and we are not sure whether it is true or
false. For example, {\em $A \equiv$ New Zealand wins more bronze medals than
Australia at the 2028 Olympics}.\pause

We can describe the degree of plausibility of $A$ using a value between 0 and 1.
For instance:
\begin{itemize}
\item $P(A) = 1$ (it is definitely true) \\
\item $P(A) = 1$ (it is definitely false) \\
\item $P(A) = 0.1$ (it is probably false) \\
\item $P(A) = 0.5$ (as certain as a coin landing heads)
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Bayesian Interpretations of Probability}
There are some language choices people use to describe what
Bayesian probabilities represent. Examples:\pause

\begin{itemize}
\item Plausibility \pause
\item Degree of confidence \pause
\item Degree of belief \pause
\item The degree to which one statement implies another
\end{itemize}

\end{frame}



\begin{frame}
\frametitle{Subjective Probabilities}
Some people say that Bayesian probabilities are subjective.
This is often true. It is certainly the case
that they depend on what information you have.\\[0.3em]\pause

Consider the statement that NZ's population is greater than 8
million people. I would assign a probability close to zero.
Someone from afar might assign a probability closer to 0.5.\\[0.3em]\pause

When different people have different probability judgments,
it is usually because they have different information or assumptions.

\end{frame}


\begin{frame}
\frametitle{Assumptions}
\begin{itemize}
\item Even though different people might have different probability
judgments, the rules linking one probability to another --- the sum
and product rule (etc) --- are consistent.\\\pause
\item When we start working on problems, we will see that some
input probabilities in the problem
are judgment calls, but other ones are calculated.\\\pause
\item The most obvious place where assumptions are needed is the
`prior' which we will meet soon, but it's not the only place
where assumptions enter.
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Updating Probabilities}
There is a well-defined procedure for updating probabilities to take new
information into account. For example, suppose you are interested in
the proposition $A$.\pause
\begin{itemize}
\item You assign a {\bf prior} probability $P(A)$.\pause
\item Then, you learn that
some related proposition $B$ is true. You should update your probability
to $P(A \given B)$, called a {\bf posterior} probability.\pause
\item If you then learn that $C$ is true, you should update
to $P(A \given B, C)$, another posterior probability.\pause
\item And so on.
\end{itemize}

\end{frame}



\begin{frame}
\frametitle{Updating Probabilities: Bayes' Rule}
Bayes' rule (derived from the product rule) gives us the procedure to
calculate updated (posterior) probabilities.

\begin{align}
P(H \given D) &= \frac{P(H) P(D\given H)}{P(D)}.
\end{align}

\pause
The terms have names:
\begin{align}
\textnormal{posterior prob.} &=
        \frac{\textnormal{prior prob.} \times \textnormal{likelihood}}{\textnormal{marginal likelihood}}
\end{align}

\end{frame}



\begin{frame}
\frametitle{Updating Probabilities: Bayes' Rule}
The statements in the previous equation were $H$ and $D$.
These stand for {\em hypothesis} and {\em data} respectively,
to indicate how we use Bayes' theorem.\\[0.5em]\pause

We usually want to know if $H$ is true, and we don't know,
so we calculate a probability for it. We usually have some
data proposition $D$ which we do know is true, so we use that.

\end{frame}


\begin{frame}
\frametitle{Interpretation of the Terms}

\begin{itemize}
\item $P(H\given D)$ is the updated (posterior) probability, which we
want.\pause
\item $P(H)$ is the initial (prior) probability. It describes
how plausible $H$ is without taking $D$ into account.\pause
\item $P(D \given H)$ is the likelihood value --- how plausible would $D$
have been if we knew $H$ was true?\pause
\item $P(D)$ is the marginal likelihood\footnote{Sometimes called the
{\bf evidence}, especially by physicists.} --- how plausible would $D$ have been
whether $H$ is true or not?
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Input and Output}
Two of the probabilities --- the prior and the likelihood --- are inputs to
the calculation, that we assign based on judgment calls or prior/external
information.\\

The other two --- the posterior and the marginal likelihood --- are outputs
that we compute.
\end{frame}


\begin{frame}
\frametitle{More Than One Hypothesis}
Usually there is more than one hypothesis of interest, so we will calculate
more than one posterior probability. For example, $P(H_1 \given D)$ and
$P(H_2 \given D)$. In fact, for any $H$, the negation $\neg H$ exists
(it means {\bf $H$ is false}), so there are always at least two hypotheses.


\end{frame}


\begin{frame}
\frametitle{First Example}
\begin{itemize}
\item There are two balls in a bag \pause
\item We don't know which of the following possibilities is true:\\\pause
{\em $BB$: Both balls are black}\\
{\em $BW$: One is black and one is white}
\end{itemize}\pause

Note: $BW = \neg BB$.
\end{frame}


\begin{frame}
\frametitle{Data}
To help us figure out which hypothesis is true, one ball is picked
from the bag. {\bf It is black}. What happens to the plausibility of
the hypothesis $BB$, that both are black?\pause

\begin{itemize}
\item[(a)] It is now more plausible
\item[(b)] It is now less plausible
\item[(c)] No change.
\end{itemize}\pause

I hope your intuition chooses (a). We will now do the calculation to
show exactly how plausible $BB$ is.


\end{frame}


\begin{frame}
\frametitle{Bayes' Box}
In the first part of the course, we will make tables of probabilities
which we call a Bayes' Box. It gives a simple view of the probabilities
involved in the problem.\\[0.5em]\pause

\begin{tabular}{|c|c|c|c|c|}
\hline
Hypothesis & Prior & Likelihood & Prior $\times$ Likelihood & Posterior \\
\hline
$BB$ & 0.5 & & & \\
$BW$ & 0.5 & & & \\
\hline
Total & 1 & & & \\
\hline
\end{tabular}

\end{frame}


\begin{frame}
\frametitle{Prior Probabilities}
In the Bayes' Box on the previous slide, I have assigned uniform (equal)
prior probabilities of 0.5 to the two hypotheses. This represents the state
of having no idea apart from the fact that there are two possibilities.\pause

\begin{alertblock}{Note}
The sum of the values in the prior column should always be 1.
The prior column forms a discrete probability distribution.
We sometimes just call it ``the prior distribution'' or just ``the prior''.
\end{alertblock}


\end{frame}



\begin{frame}
\frametitle{Bar Plot of the Prior Probabilities}

\centering
\includegraphics[width=0.7\textwidth]{images/two_balls_prior.pdf}

\end{frame}



\begin{frame}
\frametitle{More Input Needed}
To compute the posterior probabilities (which we want to do), we need
the likelihood values. These represent the probability of the data, assuming
each hypothesis is true (hypothetically), in turn. The data was
$D = $~{\bf black ball was drawn}.\pause

The values are:
\begin{align}
P(D \given BB) &= 1 \\
P(D \given BW) &= 0.5
\end{align}
Why? {\bf Imagine knowing the answer, but not knowing the data.}

\end{frame}

\begin{frame}
\frametitle{Bayes' Box}
We now have more values for our Bayes' Box.\\[0.5em]\pause
\begin{tabular}{|c|c|c|c|c|}
\hline
Hypothesis & Prior & Likelihood & Prior $\times$ Likelihood & Posterior \\
\hline
$BB$ & 0.5 & 1 & & \\
$BW$ & 0.5 & 0.5 & & \\
\hline
Total & 1 & & & \\
\hline
\end{tabular}\pause

\begin{alertblock}{Likelihoods}
We call this column the ``likelihood function'' or just ``the likelihood''.
The sum does not need to be 1, and is meaningless in
general.
\end{alertblock}

\end{frame}


\begin{frame}
\frametitle{Bayes' Box}
The rest of the Bayes' Box is not {\em assigned}, but is {\em computed}
using the rules of probability theory. Specifically, Bayes' rule applied
twice: once to get $P(BB \given D)$ and once to get $P(BW \given D)$.
It is easy to do the calculation using the Bayes' Box. First just multiply
priors by likelihoods, then sum the column:
\\[0.5em]\pause
\begin{tabular}{|c|c|c|c|c|}
\hline
Hypothesis & Prior & Likelihood & Prior $\times$ Likelihood & Posterior \\
\hline
$BB$ & 0.5 & 1 & 0.5 & \\
$BW$ & 0.5 & 0.5 & 0.25 & \\
\hline
Total & 1 & & 0.75 & \\
\hline
\end{tabular}\pause



\end{frame}


\begin{frame}
\frametitle{Bayes' Box}
We almost have the result! The priors times the likelihoods gives us the
{\em relative} updated plausibility of the two hypotheses. To become a
probability distribution, we need to force it to sum to 1. We do this
using ``normalisation'', i.e., dividing the column by its own total:\\[0.5em]\pause
\begin{tabular}{|c|c|c|c|c|}
\hline
Hypothesis & Prior & Likelihood & Prior $\times$ Likelihood & Posterior \\
\hline
$BB$ & 0.5 & 1 & 0.5 & 2/3 \\
$BW$ & 0.5 & 0.5 & 0.25 & 1/3 \\
\hline
Total & 1 & & 0.75 & 1\\
\hline
\end{tabular}\pause



\end{frame}


\begin{frame}
\frametitle{Marginal Likelihood}
The sum of the prior times likelihood column is the marginal likelihood
or evidence $P(D)$. It has two uses --- one of which we just saw.\\[0.5em]\pause

We can understand it as being the sum of the two mutually exclusive ways
$D$ could have come true --- via $BB$ or via $BW$. Mathematically this is
the {\bf partition theorem} which you might have seen before:

\begin{align}
P(D) &= P(BB)P(D \given BB) + P(BW)P(D \given BW).
\end{align}
\end{frame}


\begin{frame}
\frametitle{Posterior Probabilities}
The posterior probabilities now add up to 1 and form the posterior distribution,
or just ``the posterior''. We see that the probabilities have changed from
50:50 to 67:33 based on the data.\pause

\begin{alertblock}{Outputs}
The posterior distribution and the marginal likelihood are the outputs of the
calculation.
\end{alertblock}

\end{frame}

\begin{frame}
\frametitle{Bar Plot of the Posterior Probabilities}

\centering
\includegraphics[width=0.7\textwidth]{images/two_balls_posterior.pdf}

\end{frame}


\end{document}

